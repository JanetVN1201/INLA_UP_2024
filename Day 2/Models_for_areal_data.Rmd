---
title: "INLA for environmental sciences - Day 2, areal data modeling"
author: "Janet van Niekerk (janet.vanNiekerk@kaust.edu.sa)"
output: html_document
date: "July 2024"
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "/Users/vanniej/Documents/GitHub/INLA_UP_2024")

library("INLA")
library("DiagrammeR")
library("car")
library("ggpubr")
library("spdep")
library("RColorBrewer")
library("spatstat")
library("sp")
library("latticeExtra")
library("gridExtra")
library("gstat")
library("raster")
library("ggplot2")
library("ggfortify")
library("survival")
library("joineR")
library("BayesSurvival")
library("icenReg")
library("nloptr")
library("boot")
library("rnaturalearth")
library("leaflet")
```

## Example 1 - Besag and Besagproper models
```{r eval=FALSE, echo = TRUE}
inla.doc("besag")
```

In this example we use the North Carolina Sudden Infant Death Syndrome dataset.
```{r Example 1.a}
data(nc.sids)
head(nc.sids)
hist(nc.sids$SID74)
summary(nc.sids)
nc.sids <- st_read(system.file("shapes/sids.shp", package="spData"))

```
We see that the number of deaths is a count variable and therefore propose a Poisson regression model, i.e. 
$$y\sim Poi(E\theta)$$
with $$\theta = \exp(\eta)$$ and $E$ is the expected count. In this way, $\theta$ indicates the risk. We need to calculate the expected count for each observation,
```{r Example 1.b}
p_hat <- sum(nc.sids$SID74) / sum(nc.sids$BIR74)
nc.sids$E74 <- p_hat * nc.sids$BIR74
```
We use the NWBIR as a covariate to investigate if it has any influence on the risk of SIDS. We consider the proportion instead of the count,
```{r Example 1.c}
nc.sids$nwp_hat74 <- nc.sids$NWBIR74 / nc.sids$BIR74
```
Adding a random intercept adds an independent effect, although the counties are probably not independent in terms of socio-economic diversity. So we should rather include a structured random effect such that some "intercepts" are correlated with each other, conveying the dependence in space. Since we have space divided into discrete non-overlapping parts, we can use a Besag or BYM model.
```{r Example 1.d}
#Add besag for counties - a spatial model
#Graph - neighbourhood structure
nc.adj <- poly2nb(nc.sids)
B.nc <- nb2mat(nc.adj, style = "B")

par(mar = c(0,0,0,0))
plot(nc.sids$geometry, border="grey")
plot(nc.adj, coords = nc.sids$geometry,  add = TRUE, col = "blue", cex = 0.2)

#Add covariate to spatial dataset    
nc.sids$CNTY_ID2 <- 1:(length(nc.sids$CNTY_ID))

#Fit the spatial model
result1_sids <- 
```
The posterior summary is
```{r Example 1.e}
summary(result1_sids)
```
The two extra hyperparameters from the besagproper effect are the marginal standard deviation, $\sigma$ and the properness parameter, $d$, and their marginal posteriors are
```{r Example 1.f}
res1_sd_bym <- inla.tmarginal(function(x) sqrt(1/x), result1_sids$marginals.hyperpar$`Precision for CNTY_ID2`)
plot(res1_sd_bym, type = "l", xlab = expression(sigma), ylab = expression(paste("f(", sigma ,"|y)")))

plot(result1_sids$marginals.hyperpar$`Diagonal for CNTY_ID2`, type = "l", xlab = "d", ylab = "f(d|y)")

```
We can visually see the fit of the predictions from the model to the data,
```{r Example 1.ga}
nc.sids$fit_besag <- result1_sids$summary.fitted.values$mean*nc.sids$E74
plot(nc.sids["SID74"], breaks = seq(0,50, by = 5), main = "Observed counts")
plot(nc.sids["fit_besag"], breaks = seq(0,50, by = 5), main = "Predicted counts")

plot(nc.sids$SID74, ylab = "SIDS Counts")
points(nc.sids$E74*result1_sids$summary.fitted.values[,1], col = "purple", pch = 8, cex = 0.8)
```


## Example 2 - BYM and BYM2 models
```{r eval=FALSE, echo = TRUE}
inla.doc("bym")
inla.doc("bym2")
```
Let's revisit the NC SIDS dataset example.  
Now we add a BYM effect for the different counties,
```{r Example 2.a}
result2_sids <- 
```
The posterior summary is
```{r Example 2.b}
summary(result2_sids)
```
The two hyperparameters from the BYM effect are the marginal standard deviation, $\sigma$ and the weight parameter, $\phi$, and their marginal posteriors are
```{r Example 2.c}
res2_sd_bym <- inla.tmarginal(function(x) sqrt(1/x), result2_sids$marginals.hyperpar$`Precision for CNTY_ID2`)
plot(res2_sd_bym, type = "l", xlab = expression(sigma), ylab = expression(paste("f(", sigma ,"|y)")))
plot(result2_sids$marginals.hyperpar$`Phi for CNTY_ID2`, type = "l", xlab = expression(phi), ylab = expression(paste("f(", phi ,"|y)")))
```
We can again visually see the fit of the predictions from the model to the data,
```{r Example 2.d}
nc.sids$fit_bym <- result2_sids$summary.fitted.values$mean*nc.sids$E74
plot(nc.sids[c("SID74", "fit_besag", "fit_bym")],
       breaks = seq(0, 50, by = 5),
     main = "Observed and predicted counts")

plot(nc.sids$SID74, ylab = "SIDS Counts")
points(nc.sids$E74*result1_sids$summary.fitted.values[,1], col = "blue", pch = 10)
points(nc.sids$E74*result2_sids$summary.fitted.values[,1], col = "red", pch = 19, cex = 0.5)
```
We can visualise the spatial and iid effects from the BYM model as well.
```{r Example 2.e}
nc.sids$bym <- result2_sids$summary.random$CNTY_ID2[1:max(nc.sids$CNTY_ID2),"mean"]
plot(nc.sids[c("bym")],
       breaks = seq(-0.4,0.4, by = 0.05),
     main = "BYM component")

nc.sids$bym_besag <- result2_sids$summary.random$CNTY_ID2[1:max(nc.sids$CNTY_ID2)+max(nc.sids$CNTY_ID2),"mean"]
plot(nc.sids[c("bym_besag")],
       breaks = seq(-1,1, by = 0.1),
     main = "Besag component")

nc.sids$bym_iid <- (result2_sids$summary.random$CNTY_ID2[1:max(nc.sids$CNTY_ID2),"mean"]*
  sqrt(result2_sids$summary.hyperpar["Precision for CNTY_ID2", "mean"]) -
  result2_sids$summary.random$CNTY_ID2[1:max(nc.sids$CNTY_ID2)+max(nc.sids$CNTY_ID2),"mean"]*
  sqrt(result2_sids$summary.hyperpar["Phi for CNTY_ID2", "mean"]))/
(1-sqrt(result2_sids$summary.hyperpar["Phi for CNTY_ID2", "mean"]))

plot(nc.sids[c("bym_iid")],
       breaks = seq(-3,3, by = 0.1),
     main = "IID component")

```

When we compare the fit between models we can look at the marginal log-likelihoods, DIC or WAIC.
```{r Example 2.f}
result1_sids <- inla(SID74 ~ nwp_hat74 + f(CNTY_ID2, model = "besagproper", graph = B.nc), 
                     data = as.data.frame(nc.sids), 
                     family = "poisson",
                     control.compute = list(dic = TRUE, waic = TRUE),
                     control.predictor = list(compute = TRUE),
                     E = E74)

result2_sids <- inla(SID74 ~ nwp_hat74 + f(CNTY_ID2, model = "bym2", graph = B.nc), 
                     data = as.data.frame(nc.sids), 
                     family = "poisson",
                     control.compute = list(dic = TRUE, waic = TRUE),
                     control.predictor = list(compute = TRUE),
                     E = E74)

print(matrix(rbind(cbind(result1_sids$mlik[1], result1_sids$dic[1], result1_sids$waic[1]),
            cbind(result2_sids$mlik[1], result2_sids$dic[1], result2_sids$waic[1])),
            nrow = 2, ncol = 3,
            dimnames = list(c("Model 1 - Besag", "Model 2 - BYM"),
                            c("Marginal log-likelihood", "DIC", "WAIC")
                            )))
```
We can also do cross-validation as a means of measuring prediction performance (see https://arxiv.org/pdf/2210.04482).

```{r Example 2.cv}
result1_sids <- inla(SID74 ~ nwp_hat74, 
                     data = as.data.frame(nc.sids), 
                     family = "poisson",
                     control.compute = list(dic = TRUE, waic = TRUE,
                                            cpo = TRUE, return.marginals = FALSE, control.gcpo = list(enable = TRUE,num.level.sets = 4)),
                     control.predictor = list(compute = TRUE),
                     E = E74)

result2_sids <- inla(SID74 ~ nwp_hat74 + f(CNTY_ID2, model = "bym2", graph = B.nc), 
                     data = as.data.frame(nc.sids), 
                     family = "poisson",
                     control.compute = list(dic = TRUE, waic = TRUE,
                                            po = TRUE, return.marginals = FALSE, control.gcpo = list(enable = TRUE,num.level.sets = 4)),
                     control.predictor = list(compute = TRUE),
                     E = E74)
result1_sids$gcpo$groups[[1]]
result2_sids$gcpo$groups[[1]]

#Plot the "model-based neighbours" for LGOCV
nc.sids$res1_n <- NA
nc.sids$res2_n <- NA

nc.sids$res1_n[1] <- 1
nc.sids$res2_n[1] <- 1

nc.sids$res1_n[result1_sids$gcpo$groups[[1]]$idx[-1]] <- 2
nc.sids$res2_n[result2_sids$gcpo$groups[[1]]$idx[-1]] <- 2

plot(nc.sids["res1_n"], main = "Model-based 1 neighbours for LGOCV")
plot(nc.sids["res2_n"], main = "Model-based 2 neighbours for LGOCV")

```

The results for the model selection and validation are:
```{r Example 2.mselect}
print(matrix(rbind(cbind(result1_sids$mlik[1], result1_sids$dic[1], result1_sids$waic[1], mean(result1_sids$gcpo$gcpo)),
            cbind(result2_sids$mlik[1], result2_sids$dic[1], result2_sids$waic[1], mean(result2_sids$gcpo$gcpo))), 
            nrow = 2, ncol = 4,
            dimnames = list(c("Model 1 - Besag", "Model 2 - BYM"),
                            c("Marginal log-likelihood", "DIC", "WAIC", "G-CV score")
                            )))

```

## Example 3 - Joint disease mapping models (using Besag2 model)
We can do multivariate disease mapping when we take into account the effect of the presence or absence of other diseases simultaneously. These are treated as endogenous variables.
\begin{eqnarray*}
y_{i 1}|\lambda_{i1} &\sim& \text { Poisson }\left(E_{i 1} \lambda_{i 1}\right)\\ 
y_{i 2}|\lambda_{i2} &\sim& \text { Poisson }\left(E_{i 2} \lambda_{i 2}\right) \\
\log (\lambda_{i 1}) &=& m_{1} + \sum_{f = 1}^{F_1} \beta_f X_{i f} + \sum_{r=1}^{R_1} \rho^r(u_{i r}) + b_{i 1} + S_{i}\\
\log (\lambda_{i 2}) &=& m_{2} + \sum_{f = 1}^{F_2} \gamma_f Z_{i f} + \sum_{r=1}^{R_2} \xi^r(v_{i r})+ b_{i 2}  + a \, S_{i}, 
\label{eq:jointmeanmodel}
\end{eqnarray*}
```{r pre-work}
# read data 
merg.data <- readRDS("Data/MAP_data.RDS")

# The map 
map <- ne_countries(returnclass = "sf")

# Extract the map and compile the shape
if (T){
names(map)[names(map) == "iso_a3"] <- "ISO3"
names(map)[names(map) == "name"] <- "NAME"
map <- map[order(map$name_long),]
map$name_long[grepl("Gambia", map$name_long)] <- "Gambia"
map$name_long[map$name_long == "Republic of the Congo"] <- "Congo"

map <- map[order(map$name_long),]

# Select only the common countries from the map
sub_map <- match(map$name_long , merg.data$Common.countries)
map$cc <- sub_map
map_2 <- subset(map,map$cc!="NA" )
map_2 <- map_2[order(map_2$name_long),]

map_2$D.E = merg.data$D.E
map_2$M.E = merg.data$M.E
map_2$M.cases = merg.data$M.cases
map_2$D.cases = merg.data$D.cases
map_2$M.pop = merg.data$M.pop
map_2$D.pop = merg.data$D.pop


library(cleangeo)
rr <- clgeo_CollectionReport(map_2)
summary(rr)
issues <- rr[rr$type == NA,]
map_2_c <- clgeo_Clean(map_2)
}

# Neighbourhood graph
nb <- poly2nb(map_2_c)
nb2INLA("Data/map.adj",nb = nb)
g <- inla.read.graph(filename = "Data/map.adj")
map_2$ID = 1:length(map_2_c$level)

par(mar = c(0,0,0,0))
plot(map$geometry[map$continent == "Africa"], border = "grey")
plot(map_2_c, add = TRUE)
text(coordinates(map_2_c)[,1], coordinates(map_2_c)[,2], label = map_2$ID)
plot(nb, coords = map_2_c,  add = TRUE, col = "blue", pch = 1, cex = 0.01)

#Edit the graph to manually connect 12 and 14 & 15 and 8
if (F){
ind = c(12,14,15,8)
g1 = g
g1$nnbs[ind]=g1$nnbs[ind] + 1
g1$nbs[[12]] = c(g1$nbs[[12]], 14)
g1$nbs[[14]] = c(g1$nbs[[14]], 12)
g1$nbs[[15]] = c(g1$nbs[[15]], 8)
g1$nbs[[8]] = c(g1$nbs[[8]], 15)
g1$cc$id = rep(1, g1$n)
g1$cc$n = 1
g1$cc$nodes = 1:g1$n
g1$cc$mean = rep(1, g1$n)
  
plot(g)
dev.off()
plot(g1)
}
#OR edit the neighbourhood
if (F){
  nb1 <- nb
  nb1[[12]] <- as.integer(c(14))
  nb1[[14]] <- as.integer(c(nb[[14]], 12), length = length(nb[[14]])+1)
  nb1[[8]] <- as.integer(c(nb[[8]], 15), length = length(nb[[8]])+1)
  nb1[[15]] <- as.integer(c(nb[[15]], 8), length = length(nb[[15]])+1)

  par(mar = c(0,0,0,0))
plot(map$geometry[map$continent == "Africa"], border = "grey")
plot(map_2_c, add = TRUE)
text(coordinates(map_2_c)[,1], coordinates(map_2_c)[,2], label = map_2_c$ID)
plot(nb1, coords = map_2_c,  add = TRUE, col = "blue", pch = 1, cex = 0.01)

nb2INLA("Day 2/map1.adj",nb = nb1)
g1_alt <- inla.read.graph(filename = "Day 2/map1.adj")

plot(g1)
dev.off()
plot(g1_alt)
  }


```
Now we can model Malaria and G6PD mean incidence jointly by sharing a common spatial field using *besag2* (see https://doi.org/10.1098/rsos.230851).
```{r}
b = length(merg.data$M.cases)
y1 = c(merg.data$M.cases , rep(NA,b))
y2 = c(rep(NA,b) , merg.data$D.cases)

E1 = c(merg.data$M.E,rep(NA,b))
E2 = c(rep(NA,b) , merg.data$D.E)

yy = cbind(y1,y2)
EE = cbind(E1, E2)
mu = c(rep(1, b) , rep(2,b))
b1 = c(1:b,rep(NA ,b))
b2 = c(rep(NA,b),1:b)

ID = c(1:b , rep(NA ,b))

ID_copy = c(rep(NA , b), 1:b + b)

m = as.factor(mu)
d = data.frame(yy, m, ID, ID_copy, b1, b2)  

formula = yy ~ -1 + m + offset(log(E1))+ offset(log(E2))+
  f(ID, model = "besag2", graph=g, scale.model = T)+
  f(ID_copy, copy="ID", hyper = list(beta = list(fixed = TRUE)))+
  f(b1 , model = "bym2", graph=g, scale.model=TRUE)+
  f(b2, model = "bym2", graph=g, scale.model=TRUE)

r1 <- inla(formula,
           family = c("poisson","poisson"),
           data = d,
           verbose = F,
           control.predictor = list(compute = T))

round(r1$summary.fixed[,c(1:3,5)],3)

round(r1$summary.hyperpar[,c(1,3,5,6)],3)
```
We can plot the relative risk from the model.
```{r}
#Fitted values
map_2$fit_besag2_m <- r1$summary.fitted.values[1:b,"mean"]/map_2$M.E
map_2$fit_besag2_g <- r1$summary.fitted.values[1:b+b,"mean"]/map_2$D.E

l <- leaflet(map_2) %>% addTiles()

pal <- colorNumeric(palette = "YlOrRd", 
                    domain = seq(min(map_2$fit_besag2_m)-0.5,max(map_2$fit_besag2_m)+0.5 , by = 0.1))

l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$fit_besag2_m), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values= ~seq(min(map_2$fit_besag2_m)-0.5,max(map_2$fit_besag2_m)+0.5 , by = 0.1), 
            opacity = 0.5, title = "RR from besag2 model for malaria",
            position = "topright")

pal <- colorNumeric(palette = "YlOrRd", 
                    domain = seq(min(map_2$fit_besag2_g)-0.5,max(map_2$fit_besag2_g)+0.5 , by = 0.1))


l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$fit_besag2_g), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~seq(min(map_2$fit_besag2_g)-0.5,max(map_2$fit_besag2_g)+0.5 , by = 0.1), 
            opacity = 0.5, title = "RR from besag2 model for G6PD",
            position = "topright")


#Common spatial field
map_2$besag_field <- r1$summary.random$ID$mean[1:b]*r1$summary.hyperpar["Scale paramter a for ID", "mean"]

pal <- colorNumeric(palette = "YlOrRd", 
                    domain = seq(min(map_2$besag_field)-0.5,max(map_2$besag_field)+0.5 , by = 0.1))

l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$besag_field), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~seq(min(map_2$besag_field)-0.5,max(map_2$besag_field)+0.5 , by = 0.1), 
            opacity = 0.5, title = "Common spatial field",
            position = "topright")


#Disease-specific BYM effects
map_2$bym2_m <- r1$summary.random$b1$mean[1:b] 
map_2$bym2_g <- r1$summary.random$b2$mean[1:b] 


pal <- colorNumeric(palette = "YlOrRd", 
                    domain = seq(min(map_2$bym2_m)-0.5,max(map_2$bym2_m)+0.5 , by = 0.1))

l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$bym2_m), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~seq(min(map_2$bym2_m)-0.5,max(map_2$bym2_m)+0.5 , by = 0.1), 
            opacity = 0.5, title = "BYM values for malaria",
            position = "topright")

pal <- colorNumeric(palette = "YlOrRd", 
                    domain = seq(min(map_2$bym2_g)-0.5,max(map_2$bym2_g)+0.5 , by = 0.1))


l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$bym2_g), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~seq(min(map_2$bym2_g)-0.5,max(map_2$bym2_g)+0.5 , by = 0.1), 
            opacity = 0.5, title = "BYM values for G6PD",
            position = "topright")


```

```{r, eval = F}

#Disease-specific Besag effects
map_2$bym2_m <- r1$summary.random$b1$mean[b+1:b] 
map_2$bym2_g <- r1$summary.random$b2$mean[b+1:b] 

pal <- colorNumeric(palette = "YlOrRd", 
                    domain = seq(min(map_2$bym2_m)-0.5,max(map_2$bym2_m)+0.5 , by = 0.1))

l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$bym2_m), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~seq(min(map_2$bym2_m)-0.5,max(map_2$bym2_m)+0.5 , by = 0.1), 
            opacity = 0.5, title = "Besag values for malaria",
            position = "topright")

pal <- colorNumeric(palette = "YlOrRd", 
                    domain = seq(min(map_2$bym2_g)-0.5,max(map_2$bym2_g)+0.5 , by = 0.1))


l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$bym2_g), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~seq(min(map_2$bym2_g)-0.5,max(map_2$bym2_g)+0.5 , by = 0.1), 
            opacity = 0.5, title = "Besag values for G6PD",
            position = "topright")

# the iid for malaria
map_2$vm = (r1$summary.random$b1$mean[1:21] * sqrt(r1$summary.hyperpar$mode[3]) -  
             r1$summary.random$b1$mean[22:42] * sqrt(r1$summary.hyperpar$mode[4])) / 
  sqrt(1 - r1$summary.hyperpar$mode[4])

range(map_2$vm)

pal <- colorNumeric(palette = "YlOrRd", domain = seq(min(map_2$vm)-0.2, max(map_2$vm) + 0.5 , by = 0.1))

l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$vm), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~seq(min(map_2$vm)-0.2, max(map_2$vm) + 0.5 , by = 0.1), 
            opacity = 0.5, title = "IID of Malaria",
            position = "topright")


# iid effect for g6pd
map_2$v = (r1$summary.random$b2$mean[1:21] * sqrt(r1$summary.hyperpar$mode[5]) -  
              r1$summary.random$b2$mean[22:42] * sqrt(r1$summary.hyperpar$mode[6])) / 
              sqrt(1 - r1$summary.hyperpar$mode[6])

pal <- colorNumeric(palette = "YlOrRd", domain = seq(min(map_2$v)-0.2, max(map_2$v) + 0.5 , by = 0.1))


l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$v), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~seq(min(map_2$v)-0.2, max(map_2$v) + 0.5 , by = 0.1), 
            opacity = 0.5, title = "IID for G6PD",
            position = "topright")



```
## Example 4 - Quantile models for disease mapping
Now we can also do quantile modeling, instead of the mean risk we can model the high risk areas only and see if there are different covariate impacts for the higher levels of risk. 

\begin{eqnarray}
y_{i 1}|\lambda_{i1} &\sim& \text { Poisson }\left(E_{i1}\lambda_{i 1}\right) \notag\\
y_{i 2}|\lambda_{i2} &\sim& \text { Poisson }\left(E_{i2}\lambda_{i 2}\right) \notag\\
\log (q_{i 1, \alpha_{1}}) &=& \eta_{i 1,\alpha_{1}} =  m_{1} + \sum_{f = 1}^{F_1} \beta_f X_{i f} + \sum_{r=1}^{R_1} \rho^r(u_{i r}) + b_{i 1} + S_{i} \notag \\
\log (q_{i 2,\alpha_{2}}) &=& \eta_{i 2,\alpha_{2}} = m_{2} + \sum_{f = 1}^{F_2} \gamma_f Z_{i f} + \sum_{r=1}^{R_2} \xi^r(v_{i r})+ b_{i 2}  + c \, S_{i},\label{qa2}
\end{eqnarray}. 
In INLA we only need to add the special link function as follows:  
control.family = list(control.link = list(model = "quantile", quantile = alpha)). 
                                                      
First we model the malaria incidence quantile and thereafter the G6PD incidence, while ignoring a shared effect.


```{r pre, eval = T}
alpha0 = 0.8
r.m <- inla(formula = map_2$M.cases ~ 1 + offset(log(map_2$M.E)) +
              f(b1, model = "bym2", 
                graph = g)   ,
            family = "poisson",
            data =  merg.data,
            control.predictor = list(compute = T),
            control.family = list(control.link = list(model = "quantile",
                                                      quantile = alpha0)),
            verbose = F)

round(r.m$summary.hyperpar[,c(1,3,5,6)],3)


```


```{r}
# the quantile for G6PD only
r.d <- inla(formula = map_2$D.cases ~ 1 + offset(log(map_2$D.E))+
              f(b2,model = "bym2", 
                graph = g)  ,
            family = "poisson",
            data =  merg.data,
            control.predictor = list(compute = T),
            control.family = list(control.link = list(model = "quantile",
                                                      quantile = alpha0)),
            verbose = F)

round(r.d$summary.hyperpar[,c(1,3,5,6)],3)
```
Visualize the effects.
```{r}
# the iid EFFECT malaria
map_2$vm2 = (r.m$summary.random$b1$mean[1:21] * sqrt(r.m$summary.hyperpar$mode[1]) -  
              r.m$summary.random$b1$mean[22:42] * sqrt(r.m$summary.hyperpar$mode[2])) / 
  sqrt(1 - r.m$summary.hyperpar$mode[2])

pal <- colorNumeric(palette = "YlOrRd", domain = seq(-2.6,1.6 , by = 0.1))


l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$vm2), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~seq(-2.6,1.6 , by = 0.1), 
            opacity = 0.5, title = "IID effect for G6PD",
            position = "topright")

# the iid EFFECT g6

map_2$vd2 = (r.d$summary.random$b2$mean[1:21] * sqrt(r.d$summary.hyperpar$mode[1]) -  
              r.d$summary.random$b2$mean[22:42] * sqrt(r.d$summary.hyperpar$mode[2])) / 
  sqrt(1 - r.d$summary.hyperpar$mode[2])

pal <- colorNumeric(palette = "YlOrRd", domain = seq(-5.6,2.6 , by = 0.1))


l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$vd2), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~seq(-5.6,2.6 , by = 0.1), 
            opacity = 0.5, title = "IID effect for G6PD",
            position = "topright")



# the spatial effect for malaria

map_2$u.m2 = r.m$summary.random$b1$mean[22:42]

pal <- colorNumeric(palette = "YlOrRd", domain = seq(-5.6,2.6 , by = 0.1))


l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$u.m2), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~seq(-5.6,2.6 , by = 0.1), 
            opacity = 0.5, title = "Besag effect for Malaria",
            position = "topright")

# the spatial effect for G6PD

map_2$u.d2 = r.d$summary.random$b2$mean[22:42]


pal <- colorNumeric(palette = "YlOrRd", domain =seq(-5.6,2.6 , by = 0.1))


l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$u.d2), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~ seq(-5.6,2.6 , by = 0.1), 
            opacity = 0.5, title = "Besag effect for G6PD",
            position = "topright")


# The relative risk for malaria 

map_2$rrm = r.m$summary.fitted.values[,"mean"]/map_2$M.E
range(map_2$rrm)

pal <- colorNumeric(palette = "YlOrRd", 
                    domain = seq(0,6.3 , by = 0.1))
l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$rrm), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~seq(0,6.3 , by = 0.1), 
            opacity = 0.5, title = "RR",
            position = "topright")


# The relative risk for G6PD

map_2$rrd = r.d$summary.fitted.values[,"mean"]/map_2$D.E
range(map_2$rrd)


pal <- colorNumeric(palette = "YlOrRd", domain =seq(0, 6.3, length = 9))


l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$rrd), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~ seq(0, 6.3, length = 9), 
            opacity = 0.5, title = "RR",
            position = "topright")

# The predicted cases for Malaria 

map_2$Predicted.MM = r.m$summary.fitted.values$mean

pal <- colorNumeric(palette = "YlOrRd", domain =seq(0,40000, length =9))


l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$Predicted.MM), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~ seq(0,40000, length =9), 
            opacity = 0.5, title = "Predicted",
            position = "topright")


#Observed

l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$M.cases), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~ seq(0,40000, length =9), 
            opacity = 0.5, title = "Observed",
            position = "topright")




# The predicted cases for G6PD


map_2$Predicted.DD = r.d$summary.fitted.values$mean
range(map_2$Predicted.DD)


pal <- colorNumeric(palette = "YlOrRd", domain =seq(0,500 , by = 10))


l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$Predicted.DD), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~ seq(0,500 , by = 10), 
            opacity = 0.5, title = "Predicted",
            position = "topright")


l %>% addPolygons(color = "grey", weight = 1, 
                  fillColor = ~pal(map_2$D.cases), 
                  fillOpacity = 0.5) %>%
  addLegend(pal = pal, values = ~ seq(0,500 , by = 10), 
            opacity = 0.5, title = "Observed",
            position = "topright")


```
Now we can do a multivariate quantile disease mapping of these two diseases.
```{r, eval = T}
#Use the dataset and formula we already created for the joint mean modeling

formula = yy ~ -1 + m + offset(log(E1))+ offset(log(E2))+
  f(ID, model = "besag2", graph=g, scale.model = T)+
  f(ID_copy, copy="ID", hyper = list(beta = list(fixed = TRUE)))+
  f(b1 , model = "bym2", graph=g, scale.model=TRUE)+
  f(b2, model = "bym2", graph=g, scale.model=TRUE)

alpha0 = 0.7
r1 <- inla(formula,
           family = c("poisson","poisson"),
           
           control.family = list(list(control.link = list(model = "quantile",quantile = alpha0)),
                                 
                                 list(control.link = list(model = "quantile",
                                                          quantile = alpha0))), 
           data = d,
           verbose = F,
           control.compute = list(dic = T, waic = T, cpo = T),
           control.predictor = list(compute = T))


round(r1$summary.fixed[,c(1:3,5)],3)

round(r1$summary.hyperpar[,c(1,3,5,6)],3)

#Opposite quantiles
r1a <- inla(formula,
           family = c("poisson","poisson"),
           control.family = list(list(control.link = list(model = "quantile",quantile = alpha0)),
                                 list(control.link = list(model = "quantile",
                                                          quantile = 1-alpha0))),
           data = d,
           verbose = F,
           control.compute = list(dic = T, waic = T, cpo = T),
           control.predictor = list(compute = T))


round(r1a$summary.fixed[,c(1:3,5)],3)

round(r1a$summary.hyperpar[,c(1,3,5,6)],3)

```
Maybe the *besag2* is too strict because of the restriction a>0. We can add more flexibility with copying a besagproper model component as follows:
```{r}
#High quantile of malaria and low quantile of G6PD
alpha0 = 0.7
d1 <- d
d1$ID_copy = c(rep(NA, b),1:b)

formula1 = yy ~ -1 + m + offset(log(E1))+ offset(log(E2))+
  f(ID, model = "besagproper", graph=g) +
  f(ID_copy, copy="ID", hyper = list(beta = list(fixed = FALSE))) +
  f(b1 , model = "bym2", graph=g, scale.model=TRUE)+
  f(b2, model = "bym2", graph=g, scale.model=TRUE)

r2a <- inla(formula1,
           family = c("poisson","poisson"),
           control.family = list(list(control.link = list(model = "quantile",quantile = alpha0)),
                                 list(control.link = list(model = "quantile",
                                                          quantile = 1-alpha0))),
           data = d1,
           verbose = F,
           control.compute = list(dic = T, waic = T, cpo = T),
           control.predictor = list(compute = T))


round(r2a$summary.fixed[,c(1:3,5)],3)

round(r2a$summary.hyperpar[,c(1,3,5,6)],3)

#Median joint modeling

alpha0 = 0.5

formula1 = yy ~ -1 + m + offset(log(E1))+ offset(log(E2))+
  f(ID, model = "besagproper", graph=g) +
  f(ID_copy, copy="ID", hyper = list(beta = list(fixed = FALSE))) +
  f(b1 , model = "bym2", graph=g, scale.model=TRUE)+
  f(b2, model = "bym2", graph=g, scale.model=TRUE)

r3a <- inla(formula1,
           family = c("poisson","poisson"),
           control.family = list(list(control.link = list(model = "quantile",quantile = alpha0)),
                                 list(control.link = list(model = "quantile",
                                                          quantile = 1-alpha0))),
           data = d1,
           verbose = F,
           control.compute = list(dic = T, waic = T, cpo = T),
           control.predictor = list(compute = T))


round(r3a$summary.fixed[,c(1:3,5)],3)

round(r3a$summary.hyperpar[,c(1,3,5,6)],3)

```

## Example 5 - Non-stationary Besag model for areal data
The details are available at https://journals.sagepub.com/doi/10.1177/09622802241244613 (arXiv version https://arxiv.org/abs/2306.17236).  
The joint density function of $\pmb x$ with precision parameters $\tau_1, \tau_2, ...,\tau_P$ is defined as
    \begin{equation}
            \pi(\pmb x|\tau_{1}, \ldots, \tau_{P}) \propto \exp\Big(-\dfrac{1}{4} \sum_
            {\substack{i\text{ in sub-region } k \\ j\text{ in sub-region } l \\ i \sim j \\ i > j }} (\tau_{l} + \tau_{k} )(x_i - x_{j})^2 \Big), \quad  k, l = 1, \ldots, P,
            \label{eq::besagtype1}
        \end{equation}
    \noindent with conditional densities
       \begin{equation*}
        x_i |\pmb x_{-i}, \tau_{1}, \ldots, \tau_{P} \sim N \Big(\dfrac{1}{2}\displaystyle \sum_{\substack{i\text{ in sub-region } k \\ j\text{ in sub-region } l \\ i \sim j}} (\tau_{l} + \tau_{k})\tau_{x_i}^{-1} x_j, \tau_{x_i}^{-1}\Big),
    \end{equation*} and
    \begin{equation*}
        \tau_{x_i} = \dfrac{1}{2}\Big(n_{i} \tau_{k}  + \sum_{l} n_{il} \tau_{l}\Big).
    \end{equation*}
  
The joint PC prior for $\pmb\theta = \log\pmb\tau$ can be derived as a convolution of the PC prior for $\tau$ from the Besag model and an i.i.d. prior for the elements of $\pmb\gamma$ such that $\gamma_j\sim N(0, \sigma^2_\gamma)$, as follows
 \begin{equation}
         \pi(\pmb \theta) = 2^{-(P + 2)/2} \pi^{-P/2} \lambda \sigma^{-P}  \exp \Big(-\frac{1}{2} (\pmb \theta- \pmb 1 \overline{\theta})^T \tilde{\pmb \Sigma}^{-1} (\pmb \theta- \overline{\theta} \pmb 1) - \overline{\theta}/2 - \lambda e^{-\overline{\theta}/2}\Big),
         \label{Jointprior}
    \end{equation}

## Example 
We analyze the effects of hydrometeorological hazards on dengue risk in Brazil. To test the spatial variations in the spread of the virus in different sub-regions of Brazil, we fit dengue counts with a Poisson regression model as follows,
\begin{equation}
    \pmb y \sim \text{Poisson}(E e^{\pmb \eta}), \quad \pmb \eta = \pmb 1^T \mu + \pmb \alpha 
    \label{eq:brazildengue}
\end{equation}
\noindent where $\pmb y$ is the observed counts in November of dengue cases, $E$ is the expected number of counts , $\pmb \eta$ is the linear predictor, $\mu$ is the overall intercept, and $\pmb \alpha$ is the Besag (model 0) or flexible Besag model over space. 
```{r 1}
load("Data/brazil.RData")

ggplot(map_df) +
  theme_bw() +
  geom_sf(fill = NA) 
```
The counts are mostly low although some areas have large counts.

```{r 2}
ggplot(data) +
  geom_histogram(mapping = aes(Y), bins = 50, color = "black", fill = "grey") + xlim(0,1000) + ylim(0,500) +
  labs(fill = "") +
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(colour = "black")) +
  labs(x="dengue cases",
       y="count") 

values <- numeric(558)
for(i in 1:558) {
  values[i] <- mean(data$Y[data$S1==i]/exp(data$E[data$S1==i]))}

values[values<0.5] = "0.5"
values[values>0.5 & values<1] = "1"
values[values>1 & values<2] = "2"
values[values>2& values<5] = "3"
values[values>5] = "4"

custom_palette <- c("#f7776d", "#ffc000", "#2b8ab1", "#bbcf33", "#e76cf2")
ggplot(map_df) +
  geom_sf(aes(fill = values), lwd = 0) +
  labs(fill = "") +
  theme_void() +
  scale_fill_manual(
    values = custom_palette,
    breaks = unique(values),
    labels = c("<0.5", "0.5-1", "1-2", "2-5", "5+")) +  
  theme(legend.position = "bottom", 
        legend.title = element_blank(),
        legend.text = element_text(size=14))

#Plot of neighbors for municipalities 1 and 21
neigh_graphs <- poly2nb(as(map_df$geometry, "Spatial"), queen = FALSE)
col_lines <- rep(NA, length(neigh_graphs))
col_lines[1] = "blue"
col_lines[21] = "blue"

plot(map_df$geometry, border = "grey")
plot(neigh_graphs, coords = map_df$geometry, col = col_lines, add = T, cex = 0.1)
  
```
Now the question arises, how do we find groupings?
```{r 3}
ggplot(map_df) +
  geom_sf(aes(fill = biome_name), lwd = 0) +
  labs(fill = "") 

ggplot(map_df) +
  geom_sf(aes(fill = region_name), lwd = 0)  +
  labs(fill = "") 

```
We can formulate the flexible Besag model next.
```{r 4}
#Function of fbesag - usually in the fbesag library
if (T){
'inla.rgeneric.fbesag.model' <- function(
    cmd = c("graph", "Q", "mu", "initial", "log.norm.const",
            "log.prior", "quit"),
    theta = NULL) {
  
  sbesag <- function(R, prec, id_p, scaled_cnst, npart){
    
    get_ij <- function(g){
      
      ii <- c(); jj <- c()
      for(i in 1:g$n){
        ii <- c(ii,rep(i,g$nnbs[i]), i)
        jj <- c(jj,g$nbs[[i]], i)
      }
      return(list(i=ii,j=jj))
    }
    
    g <- INLA::inla.read.graph(R)
    
    x_scaled = c()
    for(i in 1:g$n){
      tmp <- -0.5*prec[c(id_p[g$nbs[[i]]])]
      mas_prec <- prec[id_p[i]]
      x_scaled <- c(x_scaled, tmp - 0.5*mas_prec, -sum(tmp) + 0.5*g$nnbs[i]*mas_prec + 1e-5)
    }
    r <- get_ij(g)
    return(sparseMatrix(i = r$i, j = r$j, x = scaled_cnst*x_scaled))
  }
  
  npart <- length(unique(id_p))
  dim_theta <- npart
  
  interpret.theta <- function() {
    res <- list()
    for(i in 1:dim_theta){
      res[[i]] = exp(theta[i])
    }
    return(res)
  }
  
  graph <- function(){
    require(Matrix)
    return(Matrix(W,sparse=TRUE))
  }
  
  Q <- function() {
    res <- interpret.theta()
    prec = c()
    for(i in 1:dim_theta){
      prec = c(prec, res[[i]])
    }
    
    myR <- sbesag(W, prec, id_p, scaled_cnst=scaled_cnst, npart)
    return(INLA::inla.as.sparse(myR))
  }
  
  mu <- function(){return(numeric(0))}
  
  log.norm.const <- function() {
    return (numeric(0))
  }
  
  log.prior <- function() {
    
    #p1 = 1; p2 = 1e-5 
    p1 = 0.5; p2 = 0.01
    
    lam <- - log(p2)/p1
    res <- interpret.theta()
    prec = c()
    for(i in 1:dim_theta){
      prec = c(prec, res[[i]])
    }
    
    theta_p = log(prec)
    sigm2 <- sd_sim^2
    
    mean_theta <- mean(theta_p)
    P = npart
    e = eigen(diag(P) - (1/P)*matrix(1,P,P))
    D = diag(c(1.0/e$values[1:(P-1)]))
    inv_tilda_Sigma = (1/sigm2)*e$vectors[,1:(P-1)]%*%D%*%t(e$vectors[,1:(P-1)])
    
    res1 <- log(lam) - (lam)*exp(-0.5*mean_theta) -0.5*mean_theta
    res2 <- -0.5*(theta_p-mean_theta)%*%inv_tilda_Sigma%*%(theta_p-mean_theta)
    res <- drop(res1) + drop(res2) 
    return(res)
    
    
  }
  
  initial <- function() {
    #return(initial_theta)
    return(rep(4,npart))
  }
  
  quit <- function() {
    return(invisible())
  }
  
  res <- do.call(match.arg(cmd), args = list())
  return(res)
}
}

#Model setup - usually in the fbesag library
constr.inter <- list(A = matrix(1,1,dim(graph)[1]), e = rep(0, 1))
scaled_graph = as.matrix(INLA:::inla.scale.model(graph,constr.inter))
scaled_cnst = scaled_graph[1,1]/graph[1,1]

Six_terrestrial_biomes = T
id_regions <- c()
if(Six_terrestrial_biomes){
  id_regions <- data$S4
  id_regions[which(id_regions==3)] = 2
  id_regions[which(id_regions==4)] = 3
  id_regions[which(id_regions==5)] = 4
  id_regions[which(id_regions==6)] = 5
}else{
  id_regions <- data$S3
}

#PC prior setup
precision.prior <- list(prec = list(prior = "pc.prec", param = c(0.5, 0.01)))

#Define the matrices according to fbesag
fbesag.model <- inla.rgeneric.define(inla.rgeneric.fbesag.model, W = graph, id_p = id_regions ,scaled_cnst = scaled_cnst, sd_sim = 0.15)

config = FALSE
baseformula <- Y ~ 1 + f(S1, model="generic0", Cmatrix= scaled_graph, constr= TRUE, rankdef = 1,hyper = precision.prior) +
                       f(T1, model = "rw1", constr = TRUE,  scale.model = TRUE, hyper =  list(prec = list(prior = "pc.prec", param = c(0.5, 0.01)))) 
                     
formula <- Y ~ 1 + f(S1, model = fbesag.model, constr= TRUE, rankdef=1) + 
                       f(T1, model = "rw1", constr = TRUE, scale.model = TRUE, hyper = precision.prior) 

#For computation time we use int.strategy = "eb"
#Usual besag model
model_naive <- inla(formula = baseformula, data = data, family = "poisson", offset = log(E),
                    control.inla = list(strategy = 'gaussian', int.strategy = "eb"), 
                    control.compute = list(dic = TRUE, config = config, 
                                           cpo = TRUE, return.marginals = FALSE, control.gcpo = list(enable =       TRUE, num.level.sets = 2)),
                    control.fixed = list(correlation.matrix = TRUE, 
                                         prec.intercept = 1, prec = 1),
                    control.predictor = list(link = 1, compute = TRUE))

#fbesag model
model_fbesag <- inla(formula = formula, data = data, family = "poisson", offset = log(E),
                     control.inla = list(strategy = 'gaussian', int.strategy = "eb"), 
                     control.compute = list(dic = TRUE, config = config, 
                                            cpo = TRUE, return.marginals = FALSE, control.gcpo = list(enable = TRUE, num.level.sets = 2)),
                     control.fixed = list(correlation.matrix = TRUE, 
                                          prec.intercept = 1, prec = 1),
                     control.predictor = list(link = 1, compute = TRUE))

```
The results are as follows:
```{r 5}
results <- data.frame(
  Row = c("stationary", "non-stationary", "Better?"),
  DIC = c(0, 0, 0),
  CPO = c(0, 0, 0),
  GCPO = c(0, 0, 0),
  logML = c(0, 0, 0)
)

#DIC
results$DIC[1] <- round(model_naive$dic$dic,0)
results$DIC[2] <- round(model_fbesag$dic$dic,0)
results$DIC[3] <- round(model_fbesag$dic$dic,0) < round(model_naive$dic$dic,0)

#logML
results$logML[1] <- model_naive$mlik[1]
results$logML[2] <- model_fbesag$mlik[1]
results$logML[3] <- model_fbesag$mlik[1] > model_naive$mlik[1]

#gcpo
results$GCPO[1] <- -mean(log(model_naive$gcpo$gcpo[!is.na(model_naive$gcpo$gcpo)])) 
results$GCPO[2] <- -mean(log(model_fbesag$gcpo$gcpo[!is.na(model_naive$gcpo$gcpo)]))
results$GCPO[3] <- -mean(log(model_fbesag$gcpo$gcpo[!is.na(model_naive$gcpo$gcpo)])) < -mean(log(model_naive$gcpo$gcpo[!is.na(model_naive$gcpo$gcpo)])) 

results$CPO[1] <- -mean(log(model_naive$cpo$cpo[!is.na(model_naive$cpo$cpo)])) 
results$CPO[2] <- -mean(log(model_fbesag$cpo$cpo[!is.na(model_naive$cpo$cpo)]))
results$CPO[3] <- -mean(log(model_fbesag$cpo$cpo[!is.na(model_naive$cpo$cpo)])) < -mean(log(model_naive$cpo$cpo[!is.na(model_naive$cpo$cpo)])) 

ch <- id_regions[1:558]
means <- numeric(5)
for(i in 1:5){
  means[i] <- mean(abs(model_fbesag$summary.random$S1$mean[ch==i] - model_naive$summary.random$S1$mean[ch==i]))
}

f1_mean <- model_naive$internal.summary.hyperpar$mean[1]
f2_mean <- model_fbesag$internal.summary.hyperpar$mean[1:5]

f1_sd <- model_naive$internal.summary.hyperpar$sd[1]
f2_sd <- model_fbesag$internal.summary.hyperpar$sd[1:5]


print(means)
print(results)
f1_mean - f2_mean
f1_sd - f2_sd

```

Let's visualize some of the results.
```{r}
#Estimated tau values
values <- numeric(558)
diff_m1 <- model_fbesag$internal.summary.hyperpar$mean[1:5]
for(i in 1:558) values[i] <- mean(diff_m1[id_regions[neigh_graphs[[i]]]])

ggplot(map_df) +
  geom_sf(aes(fill = values), lwd = 0) +
  scale_fill_gradient_tableau("Blue-Teal") +
  labs(fill = expression(tau[i])) +
  theme_void() 

```
```{r}
#Estimated differences of the tau's
values <- numeric(558)
diff_m1 <- c(model_fbesag$internal.summary.hyperpar$mean[1:5]) - c(model_naive$internal.summary.hyperpar$mean[1])
for(i in 1:558) values[i] <- mean(diff_m1[id_regions[neigh_graphs[[i]]]])

ggplot(map_df) +
  geom_sf(aes(fill = values), lwd = 0) +
  scale_fill_gradient2(low = "#49B8F1",
                       mid = "white",
                       high = "red") +
  labs(fill = "")  +
  theme_void()  
```
```{r}
#Estimated differences of the SD's of tau
values <- numeric(558)
diff_m1 <- c(model_fbesag$internal.summary.hyperpar$sd[1:5]) - c(model_naive$internal.summary.hyperpar$sd[1])
for(i in 1:558) values[i] <- mean(diff_m1[id_regions[neigh_graphs[[i]]]])

ggplot(map_df) +
  geom_sf(aes(fill = values), lwd = 0) +
  scale_fill_gradient2(low = "#49B8F1",
                       mid = "white",
                       high = "red") +
  labs(fill = "") +
  theme_void()  

```
We can also look at the posterior mean of the random effect from the two models.
```{r}
#Fitted values
values <- numeric(558)
values <- model_naive$summary.random$S1$mean
ggplot(map_df) +
  geom_sf(aes(fill = values), lwd = 0.1) +
  scale_fill_gradient2(low = "#49B8F1",
                       mid = "white",
                       high = "red") +
  labs(fill = "") +
  ggtitle("Posterior mean of x - Besag") +
  theme_void()

values <- numeric(558)
values <- model_fbesag$summary.random$S1$mean
ggplot(map_df) +
  geom_sf(aes(fill = values), lwd = 0.1) +
  scale_fill_gradient2(low = "#49B8F1",
                       mid = "white",
                       high = "red") +
  labs(fill = "") +
  ggtitle("Posterior mean of x - fBesag") +
  theme_void()
```
We can also look at the difference between the random effects estimated from the stationary and non-stationary model.
```{r}
#Difference in x between the two models
values <- numeric(558)
values <- c(model_fbesag$summary.random$S1$mean) - c(model_naive$summary.random$S1$mean)
ggplot(map_df) +
  geom_sf(aes(fill = values), lwd = 0.1) +
  scale_fill_gradient2(low = "#49B8F1",
                       mid = "white",
                       high = "red") +
  labs(fill = "") +
  ggtitle("Difference in the posterior mean of x") +
  theme_void()

#97.5quantile
values <- numeric(558)
values <- c(model_fbesag$summary.random$S1$'0.975quant') - c(model_naive$summary.random$S1$'0.975quant')
ggplot(map_df) +
  geom_sf(aes(fill = values), lwd = 0.1) +
  scale_fill_gradient2(low = "#49B8F1",
                       mid = "white",
                       high = "red") +
  labs(fill = "") +
  ggtitle("Difference in 97.5th percentile of x") +
  theme_void()

#2.5quantile
values <- numeric(558)
values <- c(model_fbesag$summary.random$S1$'0.025quant') - c(model_naive$summary.random$S1$'0.025quant')

ggplot(map_df) +
  geom_sf(aes(fill = values), lwd = 0.1) +
  scale_fill_gradient2(low = "#49B8F1",
                       mid = "white",
                       high = "red") +
  ggtitle("Difference in 2.5th percentile of x") +
  labs(fill = "") +
  theme_void()
```


